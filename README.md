# Multiplicaci√≥n de Matrices - High Performance Computing (HPC)

Este repositorio contiene implementaciones de multiplicaci√≥n de matrices para el curso de High Performance Computing, incluyendo versiones secuenciales, paralelas con POSIX Threads y ahora una versi√≥n paralela con procesos (`fork`) usando memoria compartida.

## üöÄ Caracter√≠sticas

- **Versi√≥n Secuencial**: Implementaci√≥n cl√°sica O(n¬≥)
- **Versi√≥n Paralela Hilos (pthreads)**: Divisi√≥n de filas, balanceo simple
- **Versi√≥n Paralela Procesos (fork + mmap)**: (Integrada ahora dentro del ejecutable unificado)
- **Versi√≥n Pthreads Optimizada**: Variantes con optimizaciones extra
- **Generaci√≥n Aleatoria**: Matrices con valores enteros aleatorios y semillas configurables
- **Medici√≥n de Rendimiento**: Tiempo de usuario, tiempo de pared y GFLOPS
- **Verificaci√≥n**: Comparaci√≥n entre resultados secuenciales y paralelos
- **An√°lisis de Speedup**: C√°lculo de aceleraci√≥n y eficiencia (wall time)

## üìÅ Archivos del Proyecto

### C√≥digo Fuente
- `matrix_multiplication.c` - Versi√≥n secuencial b√°sica
- `matrix_multiplication_pthread.c` - Versi√≥n paralela con pthreads (completa)
- `matrix_multiplication_pthread_optimized.c` - Versi√≥n paralela optimizada
- (Integrada) Versi√≥n con procesos ahora incluida dentro de `matrix_mult_all` (antes `matrix_multiplication_process.c`)
- `matrix_time_analysis.c` - An√°lisis completo de tiempos (usuario + reloj)

### Archivos de Configuraci√≥n
- `Makefile` - Automatizaci√≥n de compilaci√≥n y pruebas
- `test_matrix.sh` - Script de pruebas automatizado
- `README.md` - Documentaci√≥n del proyecto
- `.gitignore` - Archivos ignorados por Git

## üîß Compilaci√≥n

### Opci√≥n 1: Usando Makefile (Recomendado)

```bash
make                          # Versi√≥n secuencial
make matrix_mult_pthread      # Versi√≥n paralela (hilos)
make matrix_mult_pthread_opt  # Versi√≥n paralela optimizada
make matrix_mult_all          # Ejecuta secuencial + hilos + procesos
make matrix_time_analysis     # An√°lisis completo de tiempos
make all                      # Compilar todas las versiones
```

La versi√≥n con procesos dedicada se ha eliminado. Usa `matrix_mult_all` para correr las tres variantes.

### Opci√≥n 2: Compilaci√≥n Manual

```bash
# Versi√≥n secuencial
gcc -O3 -Wall -Wextra -std=c99 -o matrix_mult matrix_multiplication.c

# Versi√≥n paralela con hilos
gcc -O3 -Wall -Wextra -std=c99 -pthread -o matrix_mult_pthread matrix_multiplication_pthread.c

# Versi√≥n paralela optimizada (hilos)
gcc -O3 -march=native -Wall -Wextra -std=c99 -pthread -o matrix_mult_pthread_opt matrix_multiplication_pthread_optimized.c

# (La variante de procesos est√° incluida en matrix_mult_all)
```

## üéØ Uso

### Versi√≥n Secuencial
```bash
./matrix_mult <tama√±o> [semilla_A] [semilla_B]
# Ejemplos
./matrix_mult 100
./matrix_mult 512 123 456
```

### Versi√≥n Paralela con Hilos
```bash
./matrix_mult_pthread <tama√±o> [num_hilos] [semilla_A] [semilla_B]
# Ejemplos
./matrix_mult_pthread 1000
./matrix_mult_pthread 1000 8
./matrix_mult_pthread 1000 8 123 456
```

### Versi√≥n Comparativa Unificada (Secuencial + Hilos + Procesos)
```bash
./matrix_mult_all <tama√±o> [trabajadores] [semilla_A] [semilla_B]
# Ejemplos
./matrix_mult_all 1024
./matrix_mult_all 1024 8
./matrix_mult_all 1024 8 123 456
```

Notas:
- Si no se indica `num_hilos` o `num_procesos`, se usa el n√∫mero de CPUs detectadas.
- Las semillas garantizan reproducibilidad entre ejecuciones y entre versiones (√∫til para comparar).

## üß™ Pruebas y Benchmarks

```bash
make test                  # Pruebas b√°sicas secuenciales
make test_pthread          # Pruebas con pthreads
make benchmark_compare     # Comparaci√≥n secuencial vs paralelo (si est√° definido)
./test_matrix.sh           # Script de pruebas automatizado
```

Para comparar hilos vs procesos ahora basta una sola ejecuci√≥n:
```bash
./matrix_mult_all 1600 8 123 456
```

## üìä M√©tricas y An√°lisis

Se reportan:
- Tiempo de pared (wall time) ‚Äì base para speedup.
- Tiempo de usuario (en procesos solo refleja el padre; usar `time -v` para sumar hijos si se desea).</n- GFLOPS aproximado: `(2 * N^3) / (tiempo_wall * 1e9)`
- Speedup: `T_secuencial / T_paralelo`
- Eficiencia: `Speedup / P * 100%`

Ejemplo de interpretaci√≥n:
```
Speedup (wall): 6.10x
Eficiencia (wall): 76.25% (8 hilos)
```

## ü§î Hilos vs Procesos

| Aspecto | Hilos (pthreads) | Procesos (fork) |
|---------|------------------|-----------------|
| Memoria | Compartida impl√≠cita | Requiere `mmap`/IPC |
| Overhead creaci√≥n | Bajo | Mayor |
| Sincronizaci√≥n | Necesaria para recursos compartidos | Menos necesidad si se divide memoria sin escribir zonas comunes |
| Medici√≥n de tiempo usuario | Acumula bien en `rusage` del proceso | Necesitas sumar tiempos de hijos externamente |

Para tama√±os grandes, los procesos pueden ser un poco m√°s lentos al inicio, pero el c√≥mputo domina y el speedup debe acercarse al de pthreads si el reparto es similar.

## üîç Divisi√≥n de Trabajo

Ambas versiones paralelas dividen el trabajo por filas. Si `N` no es m√∫ltiplo de `P`, las primeras filas reciben una m√°s (`distribuci√≥n balanceada`).

## üõ† Extensiones Futuras (Ideas)
- Bloqueo / tiling para mejor uso de cach√©.
- Transponer B para acceso m√°s contiguo.
- Uso de SIMD (intrinsics) y `-march=native`.
- OpenMP para comparar facilidad de implementaci√≥n.

---
