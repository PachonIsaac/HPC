# HPCReto2 - OpenMP Monte Carlo PI Estimation

## ğŸ“‹ DescripciÃ³n del Proyecto

ImplementaciÃ³n de algoritmos Monte Carlo (Needles/Buffon y Dartboard) para el cÃ¡lculo de PI utilizando paralelizaciÃ³n con **OpenMP**. El proyecto incluye anÃ¡lisis de rendimiento, profiling, optimizaciones de CPU y memoria, y comparaciÃ³n con implementaciones previas (pthreads y fork).

### Algoritmos Implementados

1. **Buffon's Needle (Monte Carlo Needles)**
   - Simula el lanzamiento de agujas sobre lÃ­neas paralelas
   - Estima PI basÃ¡ndose en la probabilidad de que las agujas crucen las lÃ­neas

2. **Monte Carlo Dartboard**
   - Simula lanzamiento de dardos en un cuadrado con cÃ­rculo inscrito
   - Estima PI usando la relaciÃ³n Ã¡rea cÃ­rculo/cuadrado

## ğŸ“‚ Estructura del Proyecto

```
HPCReto2/
â”œâ”€â”€ Makefile                 # Sistema de compilaciÃ³n
â”œâ”€â”€ README.md               # Este archivo
â”œâ”€â”€ src/                    # CÃ³digo fuente
â”‚   â”œâ”€â”€ pi_needles_serial.c              # Needles serial (baseline)
â”‚   â”œâ”€â”€ pi_dartboard_serial.c            # Dartboard serial (baseline)
â”‚   â”œâ”€â”€ pi_needles_omp_basic.c           # Needles OpenMP bÃ¡sico
â”‚   â”œâ”€â”€ pi_dartboard_omp_basic.c         # Dartboard OpenMP bÃ¡sico
â”‚   â”œâ”€â”€ pi_needles_omp_static.c          # Needles con scheduling estÃ¡tico
â”‚   â”œâ”€â”€ pi_needles_omp_dynamic.c         # Needles con scheduling dinÃ¡mico
â”‚   â”œâ”€â”€ pi_needles_omp_guided.c          # Needles con scheduling guiado
â”‚   â”œâ”€â”€ pi_dartboard_omp_static.c        # Dartboard con scheduling estÃ¡tico
â”‚   â”œâ”€â”€ pi_dartboard_omp_dynamic.c       # Dartboard con scheduling dinÃ¡mico
â”‚   â”œâ”€â”€ pi_dartboard_omp_guided.c        # Dartboard con scheduling guiado
â”‚   â”œâ”€â”€ pi_needles_omp_optimized.c       # Needles optimizado (CPU+Mem)
â”‚   â””â”€â”€ pi_dartboard_omp_optimized.c     # Dartboard optimizado (CPU+Mem)
â”œâ”€â”€ bin/                    # Ejecutables compilados
â”œâ”€â”€ scripts/                # Scripts de automatizaciÃ³n
â”‚   â”œâ”€â”€ run_benchmarks.sh   # Ejecuta benchmarks completos
â”‚   â”œâ”€â”€ run_profiling.sh    # Ejecuta profiling (gprof, perf)
â”‚   â””â”€â”€ compare_reto1.sh    # Compara con resultados Reto1
â”œâ”€â”€ results/                # Resultados de benchmarks y profiling
â”‚   â”œâ”€â”€ benchmarks.csv      # Datos de tiempo de ejecuciÃ³n
â”‚   â”œâ”€â”€ speedup.csv         # Datos de speedup y eficiencia
â”‚   â””â”€â”€ profiling/          # Reportes de profiling
â””â”€â”€ docs/                   # AnÃ¡lisis y documentaciÃ³n
    â”œâ”€â”€ analisis_paralelizacion.md
    â”œâ”€â”€ optimizaciones.md
    â””â”€â”€ comparacion_reto1.md
```

## ğŸ› ï¸ CompilaciÃ³n

### Requisitos
- GCC con soporte OpenMP
- Make
- Linux/macOS/Unix

### Compilar todo
```bash
make all
```

### Compilar por categorÃ­as
```bash
make serial      # Solo versiones seriales
make omp_basic   # Solo OpenMP bÃ¡sico
make omp_sched   # Solo diferentes scheduling
make omp_opt     # Solo optimizadas
make profiling   # Versiones para profiling
```

### Compilar individual
```bash
make pi_needles_omp_basic
make pi_dartboard_omp_optimized
```

### Ver ayuda
```bash
make help
```

### Limpiar
```bash
make clean       # Limpia binarios
make clean-all   # Limpia todo incluyendo resultados
```

## â–¶ï¸ EjecuciÃ³n

### EjecuciÃ³n manual
```bash
# Versiones seriales
./bin/pi_needles_serial 1000000
./bin/pi_dartboard_serial 1000000

# Versiones OpenMP (controlar threads con OMP_NUM_THREADS)
export OMP_NUM_THREADS=4
./bin/pi_needles_omp_basic 1000000
./bin/pi_dartboard_omp_optimized 10000000

# Diferentes nÃºmeros de threads
for threads in 1 2 4 8 16; do
    export OMP_NUM_THREADS=$threads
    ./bin/pi_needles_omp_basic 1000000
done
```

### EjecuciÃ³n con scripts
```bash
# Benchmarks completos (mÃºltiples tamaÃ±os, mÃºltiples threads)
cd scripts
./run_benchmarks.sh

# Profiling
./run_profiling.sh

# ComparaciÃ³n con Reto1
./compare_reto1.sh
```

## ğŸ“Š Benchmarking

Los benchmarks evaluarÃ¡n:
- **Speedup**: AceleraciÃ³n respecto a versiÃ³n serial
- **Eficiencia**: QuÃ© tan bien se aprovechan los cores
- **Escalabilidad**: Comportamiento con diferentes nÃºmeros de threads
- **PrecisiÃ³n**: Exactitud del cÃ¡lculo de PI
- **Diferentes tamaÃ±os de problema**: 10^6, 10^7, 10^8, 10^9 iteraciones

## ğŸ” Profiling

Herramientas utilizadas:
- **gprof**: AnÃ¡lisis de tiempo por funciÃ³n
- **perf**: Contadores de rendimiento de CPU
- **valgrind/cachegrind**: AnÃ¡lisis de cache y memoria

## ğŸš€ Optimizaciones Aplicadas

### Nivel de Compilador
- `-O2`, `-O3`: Optimizaciones generales
- `-march=native`: Optimizaciones especÃ­ficas del CPU
- `-funroll-loops`: Desenrollado de bucles

### Nivel de OpenMP
- Diferentes scheduling policies (static, dynamic, guided)
- Ajuste de chunk size
- MinimizaciÃ³n de overhead de sincronizaciÃ³n
- ReducciÃ³n de false sharing

### Nivel de Algoritmo
- Generadores de nÃºmeros aleatorios thread-safe
- ReducciÃ³n de operaciones matemÃ¡ticas costosas
- Localidad de datos
- AlineaciÃ³n de memoria

## ğŸ“ˆ Resultados Esperados

Los resultados se guardarÃ¡n en `results/`:
- `benchmarks.csv`: Tiempos de ejecuciÃ³n
- `speedup.csv`: Speedup y eficiencia calculados
- `profiling/`: Reportes detallados de profiling

## ğŸ”„ ComparaciÃ³n con Reto1

Se compararÃ¡n los resultados con las implementaciones anteriores:
- **Pthreads**: Control manual de threads
- **Fork/Processes**: Paralelismo mediante procesos
- **OpenMP**: Directivas de alto nivel

Aspectos a comparar:
- Facilidad de implementaciÃ³n
- Rendimiento y escalabilidad
- Overhead de paralelizaciÃ³n
- Portabilidad

## ğŸ“š Referencias

- **OpenMP Specifications**: https://www.openmp.org/specifications/
- **MÃ©todo Monte Carlo**: SimulaciÃ³n estocÃ¡stica
- **Buffon's Needle**: Problema clÃ¡sico de probabilidad geomÃ©trica

## ğŸ‘¥ Autores

- Isaac Pachon

## ğŸ“… Fecha

Octubre 2025 - HPC Course

---

**Nota**: Este proyecto es parte del curso de High Performance Computing (HPC).
