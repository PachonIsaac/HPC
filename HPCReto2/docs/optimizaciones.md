# Optimizaciones Aplicadas - HPCReto2

## üìä Resumen de Implementaciones

Se han creado **12 implementaciones diferentes** de los algoritmos Monte Carlo:
- 2 versiones seriales (baseline)
- 2 versiones OpenMP b√°sicas
- 6 versiones con diferentes scheduling policies
- 2 versiones completamente optimizadas

---

## üîß Optimizaciones por Categor√≠a

### 1. **Optimizaciones de Paralelizaci√≥n (OpenMP)**

#### Directivas B√°sicas
```c
#pragma omp parallel for reduction(+:hits) schedule(static)
```

**Beneficios**:
- `parallel for`: Autom√°ticamente distribuye iteraciones
- `reduction(+:hits)`: Sincronizaci√≥n eficiente del contador
- Overhead m√≠nimo de thread management

#### Scheduling Policies Exploradas

**a) Static Scheduling**
```c
schedule(static)
```
- Divisi√≥n de trabajo en chunks de tama√±o fijo
- Menor overhead
- **Mejor para iteraciones uniformes** (nuestro caso)
- Distribuci√≥n predecible

**b) Dynamic Scheduling**
```c
schedule(dynamic, 1000)
```
- Chunks asignados din√°micamente
- Mayor overhead de sincronizaci√≥n
- √ötil para carga desbalanceada
- Chunk size de 1000 iteraciones

**c) Guided Scheduling**
```c
schedule(guided)
```
- Chunks adaptativos (grandes ‚Üí peque√±os)
- Compromiso entre static y dynamic
- Buen balanceo de carga con overhead moderado

---

### 2. **Optimizaciones de Generaci√≥n de N√∫meros Aleatorios**

#### Problema Original
```c
// ‚ùå rand() no es thread-safe
srand(time(NULL));
for (i = 0; i < n; i++) {
    x = rand();  // Race condition!
}
```

#### Soluci√≥n Implementada
```c
// ‚úÖ rand_r() con semilla por thread
unsigned int seed = (unsigned int)(i + omp_get_thread_num() * needles);
double x = ((double)rand_r(&seed) / RAND_MAX) * range;
```

**Beneficios**:
- Thread-safe
- Cada thread tiene su secuencia aleatoria
- Sin necesidad de locks

#### Versi√≥n Optimizada
```c
// Semilla √∫nica por thread (no por iteraci√≥n)
unsigned int seed = (unsigned int)(time(NULL) + tid * 12345);

#pragma omp for
for (long i = 0; i < n; i++) {
    double x = rand_r(&seed) * rand_max_inv;  // Precalculada
}
```

**Mejoras**:
- Semilla solo una vez por thread (m√°s eficiente)
- Prec√°lculo de `1.0/RAND_MAX` evita divisi√≥n repetida

---

### 3. **Optimizaciones para Evitar False Sharing**

#### Problema
```c
// ‚ùå M√∫ltiples threads modificando hits
long hits = 0;
#pragma omp parallel for
for (i = 0; i < n; i++) {
    if (condition) hits++;  // False sharing!
}
```

#### Soluci√≥n: Contadores Locales Alineados
```c
// ‚úÖ Estructura alineada a cache line (64 bytes)
typedef struct {
    long value;
    char padding[64 - sizeof(long)];
} aligned_long_t __attribute__((aligned(64)));

aligned_long_t *local_hits = calloc(num_threads, sizeof(aligned_long_t));

#pragma omp parallel
{
    int tid = omp_get_thread_num();
    long my_hits = 0;
    
    #pragma omp for nowait
    for (i = 0; i < n; i++) {
        if (condition) my_hits++;
    }
    
    local_hits[tid].value = my_hits;
}

// Reducci√≥n final sin contenci√≥n
for (i = 0; i < num_threads; i++) {
    total_hits += local_hits[i].value;
}
```

**Beneficios**:
- Cada thread escribe en su propia cache line
- Elimina invalidaciones de cache
- Reducci√≥n solo al final (una vez)
- Uso de `nowait` para eliminar barrera innecesaria

---

### 4. **Optimizaciones de CPU**

#### A) Prec√°lculo de Constantes
```c
// ‚ùå Antes: calcular en cada iteraci√≥n
for (i = 0; i < n; i++) {
    double half_length = LENGTH / 2.0;  // Repetido millones de veces
    double x = ... * (LENGTH / 2.0);
}

// ‚úÖ Despu√©s: calcular una vez
const double half_length = LENGTH / 2.0;
const double half_dist = DIST / 2.0;
const double rand_max_inv = 1.0 / RAND_MAX;

for (i = 0; i < n; i++) {
    double x = rand_r(&seed) * rand_max_inv * half_dist;
}
```

**Impacto**: Elimina millones de divisiones

#### B) Optimizaci√≥n de Operaciones Matem√°ticas

**Dartboard - Transformaci√≥n de rango**
```c
// ‚ùå Antes: 2 multiplicaciones
double x = ((double)rand_r(&seed) / RAND_MAX) * 2.0 - 1.0;

// ‚úÖ Despu√©s: 1 multiplicaci√≥n + 1 suma
double x = ((double)rand_r(&seed) * rand_max_inv);
x = x + x - 1.0;  // M√°s r√°pido que x * 2.0
```

**Beneficio**: Suma es m√°s r√°pida que multiplicaci√≥n

#### C) Flags de Compilaci√≥n
```makefile
CFLAGS_OMP_OPT = -O3 -march=native -funroll-loops
```

- **-O3**: Optimizaciones agresivas del compilador
- **-march=native**: Instrucciones espec√≠ficas del CPU
- **-funroll-loops**: Desenrolla bucles peque√±os

---

### 5. **Optimizaciones de Memoria**

#### A) Localidad de Datos
```c
// Todas las variables locales por thread
#pragma omp parallel
{
    long my_hits = 0;           // Stack local
    unsigned int seed = ...;     // Stack local
    
    for (...) {
        double x, y, theta;      // Registros o stack
        // Trabajo computacional
    }
}
```

**Beneficios**:
- Datos en cache L1 del core
- No accesos a memoria compartida en el loop
- Maximiza localidad temporal

#### B) Alineaci√≥n de Estructuras
```c
__attribute__((aligned(64)))
```
- Alinea estructuras a boundaries de cache line
- Evita que una estructura cruce m√∫ltiples cache lines
- Accesos m√°s eficientes

#### C) Reducci√≥n de Accesos a Memoria
```c
// ‚úÖ Acumulaci√≥n local, escritura una vez
long my_hits = 0;
for (i = 0; i < millions; i++) {
    if (condition) my_hits++;  // Solo incremento en registro
}
local_hits[tid].value = my_hits;  // Escritura √∫nica a memoria
```

---

## üìà Resultados Esperados de Optimizaciones

### Speedup Esperado por Optimizaci√≥n

| Optimizaci√≥n | Speedup Esperado | Raz√≥n |
|--------------|------------------|-------|
| OpenMP b√°sico (4 threads) | 3.0-3.5x | Overhead paralelizaci√≥n ~15% |
| Evitar false sharing | +10-20% | Menos invalidaciones cache |
| Prec√°lculo constantes | +5-10% | Elimina divisiones |
| Optimizar operaciones | +5-15% | Menos instrucciones |
| Flags compilador | +10-20% | Vectorizaci√≥n, inlining |
| **Total combinado** | **4.0-4.5x** | Sinergias entre optimizaciones |

### Comparaci√≥n de Scheduling

Para nuestros algoritmos (iteraciones uniformes):

| Scheduling | Performance Relativa | Overhead |
|------------|---------------------|----------|
| Static | 100% (baseline) | M√≠nimo |
| Guided | 98-99% | Bajo |
| Dynamic | 90-95% | Moderado |

**Conclusi√≥n**: Static deber√≠a ser el mejor para Monte Carlo

---

## üî¨ An√°lisis Espec√≠fico por Algoritmo

### Needles (Buffon)

**Caracter√≠sticas**:
- Operaci√≥n costosa: `sin(theta)`
- Trabajo por iteraci√≥n: Alto
- Ratio computaci√≥n/memoria: Favorable para paralelizaci√≥n

**Optimizaciones m√°s efectivas**:
1. ‚úÖ Paralelizaci√≥n (sin() es cara)
2. ‚úÖ Prec√°lculo de constantes
3. ‚úÖ Evitar false sharing
4. Lookup table para sin() (no implementada)

**Limitaciones**:
- `sin()` no se puede optimizar mucho
- Depende de librer√≠a math

### Dartboard (Circle)

**Caracter√≠sticas**:
- Operaciones simples: multiplicaci√≥n, suma
- Trabajo por iteraci√≥n: Bajo
- M√°s iteraciones t√≠picamente necesarias

**Optimizaciones m√°s efectivas**:
1. ‚úÖ Paralelizaci√≥n (overhead < beneficio)
2. ‚úÖ Evitar false sharing (cr√≠tico para ops r√°pidas)
3. ‚úÖ Optimizar operaciones (x+x vs x*2)
4. ‚úÖ Flags de compilaci√≥n (-O3 vectoriza mejor)

**Ventajas**:
- Sin funciones transcendentales
- Mejor candidato para vectorizaci√≥n SIMD
- Mayor speedup esperado

---

## üéØ Mejoras Futuras Posibles

### No Implementadas (pero posibles)

1. **SIMD Vectorization Manual**
```c
#pragma omp simd
for (i = 0; i < n; i += 4) {
    // Procesar 4 elementos simult√°neamente
}
```

2. **Generadores Aleatorios M√°s R√°pidos**
- PCG (Permuted Congruential Generator)
- xorshift
- Menor calidad pero 2-3x m√°s r√°pido

3. **Lookup Tables para sin()**
```c
double sin_table[1000];
// Pre-calcular valores comunes
```

4. **NUMA Awareness**
```c
#pragma omp parallel proc_bind(close)
```

5. **Prefetching**
```c
__builtin_prefetch(data, 0, 3);
```

---

## ‚úÖ Conclusiones

### Optimizaciones Implementadas

‚úÖ **Nivel de Paralelizaci√≥n**:
- OpenMP parallel for
- Reduction clauses
- 3 scheduling policies

‚úÖ **Nivel de Algoritmo**:
- Thread-safe random generators
- Evitar false sharing
- Contadores locales

‚úÖ **Nivel de CPU**:
- Prec√°lculo de constantes
- Optimizaci√≥n de operaciones
- Flags agresivos de compilaci√≥n

‚úÖ **Nivel de Memoria**:
- Alineaci√≥n de estructuras
- Localidad de datos
- Minimizar accesos compartidos

### Impacto Medido (Preliminar)

Con 4 threads en 10M iteraciones:

**Needles**:
- Serial: 0.268s
- OpenMP Basic: 0.068s ‚Üí **Speedup: 3.94x**
- OpenMP Optimized: 0.093s (variabilidad)

**Dartboard**:
- Serial: 0.161s
- OpenMP Basic: 0.067s ‚Üí **Speedup: 2.40x**
- OpenMP Optimized: 0.056s ‚Üí **Speedup: 2.88x**

### Observaciones

1. Needles tiene mejor speedup (m√°s trabajo por iteraci√≥n)
2. Optimizaciones muestran resultados variables (necesita m√°s runs)
3. Scheduling policy tiene impacto moderado
4. False sharing cr√≠tico para operaciones r√°pidas

---

**Pr√≥ximos pasos**: Benchmarking exhaustivo y an√°lisis de profiling para validar optimizaciones.
